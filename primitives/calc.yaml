---
name: "calc"
description: "This file contains arithmetic primitives."
...
---
primitive_name: "add"
brief_description: "Adds two vector registers."
parameters:
   - ctype: "const typename Vec::register_type"
     name: "vec_a"
     description: "First vector."
   - ctype: "const typename Vec::register_type"
     name: "vec_b"
     description: "Second vector."
returns:
   ctype: "typename Vec::register_type"
   description: "Vector containing result of the addition."
testing: #optional
   -  test_name: "zero_cornercase"
      requires: ["set1", "loadu", "hadd"]
      includes: ["<cstddef>"]
      implementation: |
         using T = typename Vec::base_type;
         std::size_t element_count = 1024;
         testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false};
         bool allOk = true;
         auto reference_data_ptr = test_helper.data_ref();
         auto reference_result_ptr = test_helper.result_ref();
         auto test_data_ptr = test_helper.data_target();
         auto test_result_ptr = test_helper.result_target();
         for(std::size_t i = 0; i < element_count - Vec::vector_element_count(); i+=Vec::vector_element_count()) {
            std::size_t tester_idx = 0;
            for(size_t j = i; j < i + Vec::vector_element_count(); ++j) {
               reference_result_ptr[tester_idx++] = reference_data_ptr[j];
            }
            auto vec = set1<Vec>( 0 );
            auto elements = loadu<Vec>(&test_data_ptr[i]);
            vec = add<Vec>(vec, elements);
            storeu<Vec>( test_result_ptr, vec );
            test_helper.synchronize();
            allOk &= test_helper.validate();
         }
               return allOk;
   -  test_name: "running_sum_w_epsilon"
      requires: ["set1", "loadu", "hadd"]
      includes: ["<cstddef>"]
      implementation: |
         using T = typename Vec::base_type;
         std::size_t element_count = 1024;
         testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false };
         bool allOk = true;
         auto reference_data_ptr = test_helper.data_ref();
         auto reference_result_ptr = test_helper.result_ref();
         auto test_data_ptr = test_helper.data_target();
         auto test_result_ptr = test_helper.result_target();
         auto vec = set1<Vec>( 0 );
         for(std::size_t i = 0; i < element_count - 2*Vec::vector_element_count(); i+=2*Vec::vector_element_count()) {
            std::size_t tester_idx = 0;
            for(size_t j = i; j < i + Vec::vector_element_count(); j++) {
               reference_result_ptr[tester_idx++] = reference_data_ptr[j]+reference_data_ptr[j+Vec::vector_element_count()];
            }
            auto elements_vec1 = loadu<Vec>(&test_data_ptr[i]);
            auto elements_vec2 = loadu<Vec>(&test_data_ptr[i+Vec::vector_element_count()]);
            vec = add<Vec>(elements_vec1, elements_vec2);
            storeu<Vec>( test_result_ptr, vec );
            test_helper.synchronize();
            allOk &= test_helper.validate();
         }
         return allOk;
definitions:
#CUDA
   - target_extension: "cuda"
     ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double"]
     lscpu_flags: ["cuda"]
     vector_length_agnostic: True
     implementation: |
        typename Vec::register_type vec_c;
        size_t element_count = VectorSize / (sizeof({{ ctype }}) * 8);
        constexpr auto add = +[]({{ ctype }} a, {{ ctype }} b) { return a + b; };
        return launch_elemenwise_op<typename Vec::register_type, add>(vec_a, vec_b, VectorSize);
#INTEL - AVX512
   - target_extension: "avx512"
     ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
     lscpu_flags: ['avx512f']
     specialization_comment: "Signed addition."
     implementation: "return _mm512_add_epi{{ intrin_tp[ctype][1] }}(vec_a, vec_b);"
   - target_extension: "avx512"
     ctype: ["float", "double"]
     lscpu_flags: ['avx512f']
     implementation: "return _mm512_add_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
#INTEL - AVX2
   - target_extension: "avx2"
     ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
     lscpu_flags: ['avx2']
     specialization_comment: "Signed addition."
     implementation: "return _mm256_add_epi{{ intrin_tp[ctype][1] }}(vec_a, vec_b);"
   - target_extension: "avx2"
     ctype: ["float", "double"]
     lscpu_flags: ['avx']
     implementation: "return _mm256_add_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
#INTEL - SSE
   - target_extension: "sse"
     ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
     lscpu_flags: ['sse2']
     specialization_comment: "Signed addition."
     implementation: "return _mm_add_epi{{ intrin_tp[ctype][1] }}(vec_a, vec_b);"
   - target_extension: "sse"
     ctype: ["float"]
     lscpu_flags: ['sse']
     implementation: "return _mm_add_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
   - target_extension: "sse"
     ctype: ["double"]
     lscpu_flags: ['sse2']
     implementation: "return _mm_add_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
#ARM - NEON
   - target_extension: "neon"
     ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double"]
     lscpu_flags: [ 'neon' ]
     implementation: "return vaddq_{{ intrin_tp_full[ctype] }}( vec_a, vec_b );"
#SCALAR
   - target_extension: "scalar"
     ctype: [ "uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double" ]
     lscpu_flags: []
     implementation: "return vec_a + vec_b;"
#INTEL - FPGA
   - target_extension: "fpga"
     ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "float", "uint64_t", "int64_t", "double"]
     lscpu_flags: ["fpga"]
     vector_length_agnostic: True
     implementation: |
        using T = typename Vec::register_type;
        T result; //initialize the result
        #pragma unroll
        for(int i = 0; i < Vec::vector_element_count(); ++i) {
          result[i] = vec_a[i] + vec_b[i];
        }
        return result;
---
primitive_name: "add"
functor_name: "mask_add"
brief_description: "Adds two vector registers, depending on a mask: result[*] = (m[*])? vec_a[*]+vec_b[*] : vec_a[*]."
parameters:
  - ctype: "const typename Vec::mask_type"
    name: "mask"
    description: "Vector mask register indicating which elements should be added."
  - ctype: "const typename Vec::register_type"
    name: "vec_a"
    description: "First vector."
  - ctype: "const typename Vec::register_type"
    name: "vec_b"
    description: "Second vector."
returns:
  ctype: "typename Vec::register_type"
  description: "Vector containing result of the addition."
definitions:
#INTEL - AVX512
  - target_extension: "avx512"
    ctype: ["float", "double"]
    lscpu_flags: ["avx512f"]
    implementation: "return _mm512_mask_add_{{ intrin_tp_full[ctype] }}(vec_a, mask, vec_a, vec_b);"
#INTEL - AVX2
  - target_extension: "avx2"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["avx"]
    implementation: "return _mm256_add_epi{{ intrin_tp[ctype][1] }}(vec_a, _mm256_and_si256(vec_b, mask));"
  - target_extension: "avx2"
    ctype: ["float", "double"]
    lscpu_flags: ["avx"]
    implementation: "return _mm256_add_{{ intrin_tp_full[ctype] }}(vec_a, _mm256_and_{{ intrin_tp_full[ctype] }}(vec_b, mask));"
#INTEL - SSE
  - target_extension: "sse"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["sse2"]
    implementation: "return _mm_add_epi{{ intrin_tp[ctype][1] }}(vec_a, _mm_and_si128(vec_b, mask));"
  - target_extension: "sse"
    ctype: ["float"]
    lscpu_flags: ["sse"]
    implementation: "return _mm_add_ps(vec_a, _mm_and_ps(vec_b, mask));"
  - target_extension: "sse"
    ctype: ["double"]
    lscpu_flags: ["sse2"]
    implementation: "return _mm_add_pd(vec_a, _mm_and_pd(vec_b, mask));"
---
primitive_name: "mul"
brief_description: "Multiplies two vector registers."
parameters:
   - ctype: "const typename Vec::register_type"
     name: "vec_a"
     description: "First vector."
   - ctype: "const typename Vec::register_type"
     name: "vec_b"
     description: "Second vector."
returns:
   ctype: "typename Vec::register_type"
   description: "Vector containing result of the multiplication."
testing: #optional
   -  requires: ["loadu", "storeu"]
      includes: ["<cstddef>"]
      implementation: |
         using T = typename Vec::base_type;
         std::size_t element_count = 1024;
         testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false };
         bool allOk = true;
         auto reference_data_ptr = test_helper.data_ref();
         auto reference_result_ptr = test_helper.result_ref();
         auto test_data_ptr = test_helper.data_target();
         auto test_result_ptr = test_helper.result_target();
         for(std::size_t i = 0; i < element_count - (2*Vec::vector_element_count()); i+=(2*Vec::vector_element_count())) {
            std::size_t j = i;
            for(; j < i + Vec::vector_element_count(); ++j) {
               reference_result_ptr[j-i] = reference_data_ptr[j];
            }
            for(; j < i + (2*Vec::vector_element_count()); ++j) {
               reference_result_ptr[j-(i+Vec::vector_element_count())] *= reference_data_ptr[j];
            }
            auto vec_a = loadu<Vec>(&test_data_ptr[i]);
            auto vec_b = loadu<Vec>(&test_data_ptr[i+Vec::vector_element_count()]);
            auto vec_result = mul<Vec>(vec_a, vec_b);
            storeu<Vec>(test_result_ptr, vec_result);
            test_helper.synchronize();
            allOk &= test_helper.validate();
         }
         return allOk;
definitions:
#INTEL - AVX512
   - target_extension: "avx512"
     ctype: ["float", "double"]
     lscpu_flags: ["avx512f"]
     implementation: "return _mm512_mul_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
   - target_extension: "avx512"
     ctype: ["uint16_t"]
     lscpu_flags: ["avx512bw"]
     specialization_comment: "Signed multiplication."
     implementation: "return _mm512_mullo_epi16(vec_a, vec_b);"
   - target_extension: "avx512"
     ctype: ["int16_t"]
     lscpu_flags: ["avx512bw"]
     implementation: "return _mm512_mullo_epi16(vec_a, vec_b);"
   - target_extension: "avx512"
     ctype: ["uint32_t", "int32_t"]
     lscpu_flags: ["avx512f"]
     specialization_comment: "Signed multiplication."
     implementation: "return _mm512_mullo_epi32(vec_a, vec_b);"
   - target_extension: "avx512"
     ctype: ["uint64_t", "int64_t"]
     lscpu_flags: ["avx512dq"]
     specialization_comment: "Signed multiplication."
     implementation: "return _mm512_mullo_epi64(vec_a, vec_b);"
   - target_extension: "avx512"
     ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
     lscpu_flags: ["avx512f"]
     is_native: False
     includes: ["<array>", "<cstddef>"]
     implementation: |
        alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_a;
        alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_b;
        _mm512_store_si512(reinterpret_cast<void*>(buffer_a.data()), vec_a);
        _mm512_store_si512(reinterpret_cast<void*>(buffer_b.data()), vec_b);
        for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
           buffer_a[i] *= buffer_b[i];
        }
        return _mm512_load_si512(reinterpret_cast<void const *>(buffer_a.data()));
#INTEL - AVX2
   - target_extension: "avx2"
     ctype: ["float", "double"]
     lscpu_flags: ["avx"]
     implementation: "return _mm256_mul_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
   - target_extension: "avx2"
     ctype: ["uint16_t", "int16_t"]
     lscpu_flags: ["avx2"]
     specialization_comment: "Signed multiplication."
     implementation: "return _mm256_mullo_epi16(vec_a, vec_b);"
   - target_extension: "avx2"
     ctype: ["uint32_t", "int32_t"]
     lscpu_flags: ["avx2"]
     specialization_comment: "Signed multiplication."
     implementation: "return _mm256_mullo_epi32(vec_a, vec_b);"
   - target_extension: "avx2"
     ctype: ["uint64_t", "int64_t"]
     lscpu_flags: ["avx512dq", "avx512vl"]
     specialization_comment: "Signed multiplication."
     implementation: "return _mm256_mullo_epi64(vec_a, vec_b);"
   - target_extension: "avx2"
     ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
     lscpu_flags: ["avx"]
     is_native: False
     includes: ["<array>", "<cstddef>"]
     implementation: |
        alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_a;
        alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_b;
        _mm256_store_si256(reinterpret_cast<__m256i*>(buffer_a.data()), vec_a);
        _mm256_store_si256(reinterpret_cast<__m256i*>(buffer_b.data()), vec_b);
        for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
           buffer_a[i] *= buffer_b[i];
        }
        return _mm256_load_si256(reinterpret_cast<__m256i const *>(buffer_a.data()));
#INTEL - SSE
   - target_extension: "sse"
     ctype: ["float"]
     lscpu_flags: ["sse"]
     implementation: "return _mm_mul_ps(vec_a, vec_b);"
   - target_extension: "sse"
     ctype: ["double"]
     lscpu_flags: ["sse2"]
     implementation: "return _mm_mul_pd(vec_a, vec_b);"
   - target_extension: "sse"
     ctype: ["uint16_t", "int16_t"]
     lscpu_flags: ["sse2"]
     specialization_comment: "Signed multiplication."
     implementation: "return _mm_mullo_epi16(vec_a, vec_b);"
   - target_extension: "sse"
     ctype: ["uint32_t", "int32_t"]
     lscpu_flags: ["sse4_1"]
     specialization_comment: "Signed multiplication."
     implementation: "return _mm_mullo_epi32(vec_a, vec_b);"
   - target_extension: "sse"
     ctype: ["uint64_t", "int64_t"]
     lscpu_flags: ["avx512dq", "avx512vl"]
     specialization_comment: "Signed multiplication."
     implementation: "return _mm_mullo_epi64(vec_a, vec_b);"
   - target_extension: "sse"
     ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
     lscpu_flags: ["sse2"]
     is_native: False
     includes: ["<array>", "<cstddef>"]
     implementation: |
        alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_a;
        alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_b;
        _mm_store_si128(reinterpret_cast<__m128i*>(buffer_a.data()), vec_a);
        _mm_store_si128(reinterpret_cast<__m128i*>(buffer_b.data()), vec_b);
        for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
           buffer_a[i] *= buffer_b[i];
        }
        return _mm_load_si128(reinterpret_cast<__m128i const *>(buffer_a.data()));
#ARM - NEON
   - target_extension: "neon"
     ctype: ["uint8_t", "uint16_t", "uint32_t", "int8_t", "int16_t", "int32_t", "float", "double"]
     lscpu_flags: [ 'neon' ]
     implementation: "return vmulq_{{ intrin_tp_full[ctype] }}( vec_a, vec_b );"
   - target_extension: "neon"
     ctype: ["uint64_t", "int64_t"]
     lscpu_flags: [ 'neon' ]
     is_native: False
     implementation: |
        //Found this on stackoverflow. This seems like an overkill. Maybe an extract and scalar multiply would do the trick more efficient.
        //@todo: benchmark this.
        const auto ac = vmovn_{{ intrin_tp[ctype][0] }}64(vec_a);
        const auto pr = vmovn_{{ intrin_tp[ctype][0] }}64(vec_b);
        const auto hi = vmulq_{{ intrin_tp[ctype][0] }}32(vreinterpretq_{{ intrin_tp[ctype][0] }}32_{{ intrin_tp[ctype][0] }}64(vec_b), vrev64q_{{ intrin_tp[ctype][0] }}32(vreinterpretq_{{ intrin_tp[ctype][0] }}32_{{ intrin_tp[ctype][0] }}64(vec_a)));
        return vmlal_{{ intrin_tp[ctype][0] }}32(vshlq_n_{{ intrin_tp[ctype][0] }}64(vpaddlq_{{ intrin_tp[ctype][0] }}32(hi), 32), ac, pr);
#SCALAR
   - target_extension: "scalar"
     ctype: [ "uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double" ]
     lscpu_flags: [ ]
     implementation: "return vec_a * vec_b;"
---
primitive_name: "hadd"
brief_description: "Reduces the elements to a sum."
parameters:
   - ctype: "const typename Vec::register_type"
     name: "value"
     description: "Input vector."
returns:
   ctype: "typename Vec::base_type"
   description: "Scalar value after adding all elements in the vector."
testing:
   -  requires: ["set1"]
      includes: ["<cstddef>", "<algorithm>", "<limits>"]
      implementation: |
         using T = typename Vec::base_type;
         testing::test_memory_helper_t<Vec> test_helper{1, false};
         bool allOk = true;
         auto reference_result_ptr = test_helper.result_ref();
         auto test_result_ptr = test_helper.result_target();
         const std::size_t limit = std::min( (size_t) 4096, (size_t) std::numeric_limits<T>::max() / Vec::vector_element_count() );
         for(std::size_t i = 0; i < limit; ++i) {
            *reference_result_ptr =  Vec::vector_element_count() * i;
            auto vec = set1<Vec>(i);
            *test_result_ptr = hadd<Vec>(vec);
            test_helper.synchronize();
            allOk &= test_helper.validate();
         }
         return allOk;
definitions:
#INTEL - FPGA
   - target_extension: "fpga"
     ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "float"]
     lscpu_flags: ["fpga"]
     vector_length_agnostic: True
     implementation: |
        typename Vec::register_type result{};
        #pragma unroll
        for(size_t i = 0; i < Vec::vector_element_count(); ++i) { result[i] = value[i]; }
        #pragma unroll cilog2(Vec::vector_element_count())
        for(size_t current_width = (Vec::vector_element_count()>>1); current_width >= 1; current_width>>=1) {
            for(size_t i = 0; i < current_width; ++i) {
                result[i] = result[(i<<1)] + result[(i<<1)+1];
            }
        }
        return result[0];
# using T = typename Vec::base_type;
# T result = 0; //initialize the result
# #pragma unroll
# for(int i = 0; i < Vec::vector_element_count(); i+=16) {
#   T add_1_1 = value[ 0] + value[ 1];
#   T add_1_2 = value[ 2] + value[ 3];
#   T add_1_3 = value[ 4] + value[ 5];
#   T add_1_4 = value[ 6] + value[ 7];
#   T add_1_5 = value[ 8] + value[ 9];
#   T add_1_6 = value[10] + value[11];
#   T add_1_7 = value[12] + value[13];
#   T add_1_8 = value[14] + value[15];

#   T add_2_1 = add_1_1 + add_1_2;
#   T add_2_2 = add_1_3 + add_1_4;
#   T add_2_3 = add_1_5 + add_1_6;
#   T add_2_4 = add_1_7 + add_1_8;

#   T add_3_1 = add_2_1 + add_2_2;
#   T add_3_2 = add_2_3 + add_2_4;

#   result += add_3_1 + add_3_2;
# }
# return result;
   - target_extension: "fpga"
     ctype: ["uint64_t", "int64_t", "double"]
     lscpu_flags: ["fpga"]
     vector_length_agnostic: True
     implementation: |
        using T = typename Vec::base_type;
        T result = 0; //initialize the result
        #pragma unroll
        for(int i = 0; i < Vec::vector_element_count(); i+=16) {
          T add_1_1 = value[ 0] + value[ 1];
          T add_1_2 = value[ 2] + value[ 3];
          T add_1_3 = value[ 4] + value[ 5];
          T add_1_4 = value[ 6] + value[ 7];

          T add_2_1 = add_1_1 + add_1_2;
          T add_2_2 = add_1_3 + add_1_4;

          result += add_2_1 + add_2_2;
        }
        return result;
#INTEL - AVX512
   - target_extension: "avx512"
     ctype: ["float", "double"]
     lscpu_flags: ["avx512f"]
     specialization_comment: "Be aware, that this intrinsic is flagged as 'sequence' by INTEL."
     implementation: "return _mm512_reduce_add_{{ intrin_tp_full[ctype] }}(value);"
   - target_extension: "avx512"
     ctype: ["uint32_t", "uint64_t", "int32_t", "int64_t"]
     lscpu_flags: ["avx512f"]
     specialization_comment: "Signed Addition. Be aware, that this intrinsic is flagged as 'sequence' by INTEL."
     implementation: "return _mm512_reduce_add_epi{{ intrin_tp[ctype][1] }}(value);"
   - target_extension: "avx512"
     ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t"]
     lscpu_flags: ["avx512f"]
     is_native: False
     includes: ["<array>", "<cstddef>"]
     implementation: |
        alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer;
        typename Vec::base_type result = 0;
        _mm512_store_si512(reinterpret_cast<void*>(buffer.data()), value);
        for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
           result += buffer[i];
        }
        return result;
#INTEL - AVX2
   - target_extension: "avx2"
     ctype: ["double"]
     specialization_comment: "This instruction needs sse3. However, most intel cpus only provide ssse3 (which is a superset sse3)."
     lscpu_flags: ["sse2", "ssse3", "avx"]
     is_native: False
     implementation: |
       //https://stackoverflow.com/questions/49941645/get-sum-of-values-stored-in-m256d-with-sse-avx
       __m128d vlow  = _mm256_castpd256_pd128(value);
       __m128d vhigh = _mm256_extractf128_pd(value, 1);
       vlow  = _mm_add_pd(vlow, vhigh);
       __m128d high64 = _mm_unpackhi_pd(vlow, vlow);
       return  _mm_cvtsd_f64(_mm_add_sd(vlow, high64));
   - target_extension: "avx2"
     ctype: ["float"]
     specialization_comment: "This instruction needs sse3. However, most intel cpus only provide ssse3 (which is a superset sse3)."
     lscpu_flags: ["sse", "sse2", "ssse3", "avx"]
     is_native: False
     implementation: |
        __m128 vlow  = _mm256_castps256_ps128(value);
        __m128 vhigh = _mm256_extractf128_ps(value, 1);
        vlow = _mm_add_ps(vlow, vhigh);
        __m128 res = _mm_hadd_ps(vlow, vlow);
        return _mm_cvtss_f32(res) + _mm_cvtss_f32(_mm_castsi128_ps(_mm_bsrli_si128(_mm_castps_si128(res),sizeof(float))));
   - target_extension: "avx2"
     ctype: ["uint64_t", "int64_t"]
     lscpu_flags: ["sse2", "avx"]
     specialization_comment: "Signed Addition."
     is_native: False
     implementation: |
        __m128i vlow = _mm256_castsi256_si128(value);
        __m128i vhigh = _mm256_extractf128_si256(value, 1);
        vlow = _mm_add_epi64(vlow, vhigh);
        __m128i high64 = _mm_unpackhi_epi64(vlow, vlow);
        return _mm_cvtsi128_si64(_mm_add_epi64(vlow, high64));
   - target_extension: "avx2"
     ctype: ["uint32_t", "int32_t"]
     specialization_comment: "Signed Addition. This instruction needs sse3. However, most intel cpus only provide ssse3 (which is a superset sse3)."
     lscpu_flags: ["sse2", "ssse3", "avx"]
     is_native: False
     implementation: |
        __m128i vlow = _mm256_castsi256_si128(value);
        __m128i vhigh = _mm256_extractf128_si256(value, 1);
        vlow = _mm_add_epi32(vlow, vhigh);
        __m128i res = _mm_hadd_epi32(vlow, vlow);
        return _mm_cvtsi128_si32(res) + _mm_cvtsi128_si32(_mm_bsrli_si128(res,sizeof(uint32_t)));
   - target_extension: "avx2"
     ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t"]
     lscpu_flags: ["avx"]
     is_native: False
     includes: ["<array>", "<cstddef>"]
     implementation: |
         alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer;
         typename Vec::base_type result = 0;
         _mm256_store_si256(reinterpret_cast<__m256i*>(buffer.data()), value);
         for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
            result += buffer[i];
         }
         return result;
#INTEL - SSE
   - target_extension: "sse"
     ctype: ["double"]
     lscpu_flags: ["sse2"]
     is_native: False
     implementation: |
      return _mm_cvtsd_f64(value) + _mm_cvtsd_f64(_mm_castsi128_pd(_mm_bsrli_si128(_mm_castpd_si128(value),sizeof(double))));
   - target_extension: "sse"
     ctype: ["float"]
     specialization_comment: "This instruction needs sse3. However, most intel cpus only provide ssse3 (which is a superset sse3)."
     lscpu_flags: ["sse", "sse2", "ssse3"]
     is_native: False
     implementation: |
        auto res = _mm_hadd_ps(value, value);
        return _mm_cvtss_f32(res) + _mm_cvtss_f32(_mm_castsi128_ps(_mm_bsrli_si128(_mm_castps_si128(res),sizeof(float))));
   - target_extension: "sse"
     ctype: ["uint64_t", "int64_t"]
     lscpu_flags: ["sse2", "avx"]
     specialization_comment: "Signed Addition."
     is_native: False
     implementation: |
      return _mm_cvtsi128_si64(value) + _mm_cvtsi128_si64(_mm_bsrli_si128(value,sizeof(uint64_t)));
   - target_extension: "sse"
     ctype: ["uint32_t", "int32_t"]
     lscpu_flags: ["sse2", "ssse3", "avx"]
     specialization_comment: "Signed Addition."
     is_native: False
     implementation: |
      auto res = _mm_hadd_epi32(value, value);
                     return _mm_cvtsi128_si32(res) + _mm_cvtsi128_si32(_mm_bsrli_si128(res,sizeof(uint32_t)));
   - target_extension: "sse"
     ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t"]
     lscpu_flags: ["sse2"]
     is_native: False
     includes: ["<array>", "<cstddef>"]
     implementation: |
        alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer;
        typename Vec::base_type result = 0;
        _mm_store_si128(reinterpret_cast<__m128i *>(buffer.data()), value);
        for  (std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
             result += buffer[i];
        }
        return result;
#ARM - NEON
   - target_extension: "neon"
     ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double"]
     lscpu_flags: [ 'neon' ]
     implementation: "return vaddvq_{{ intrin_tp_full[ctype] }}( value );"
#SCALAR
   - target_extension: "scalar"
     ctype: [ "uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double" ]
     lscpu_flags: [ ]
     implementation: "return value;"
---
primitive_name: "min"
brief_description: "compares the values of 2 vectors and returns a vector with the minimum of each corrisponding values"
parameters:
    - ctype: "const typename Vec::register_type"
      name: "vec_a"
      description: "First vector"
    - ctype: "const typename Vec::register_type"
      name: "vec_b"
      description: "Second vector"
returns:
    ctype: "typename Vec::register_type"
    description: "Vector containing result of the comparison"
testing: 
   - test_name: "min_general_case"
     requires: ["set1", "loadu"]
     includes: ["<cstddef>"]
     implementation: |
        using T = typename Vec::base_type;
        const std::size_t element_count = 2048;
        testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false};
        bool allOk = true;
        auto reference_data_ptr = test_helper.data_ref();
        auto reference_result_ptr = test_helper.result_ref();
        auto test_data_ptr = test_helper.data_target();
        auto test_result_ptr = test_helper.result_target();
        auto vec = set1<Vec>(0);
        for(std::size_t i = 0; i < element_count / 2; i += Vec::vector_element_count()){
          std::size_t tester_idx = 0;
          for(size_t j = i; j < i + Vec::vector_element_count(); j++){  
            if(reference_data_ptr[j] < reference_data_ptr[j + (element_count/2)]){
              reference_result_ptr[tester_idx++] = reference_data_ptr[j];
            } else {
              reference_result_ptr[tester_idx++] = reference_data_ptr[j + (element_count/2)];
            } 
          }
          auto elements_vec1 = loadu<Vec>(&test_data_ptr[i]);
          auto elements_vec2 = loadu<Vec>(&test_data_ptr[i + (element_count/2)]);
          vec = min<Vec>(elements_vec1, elements_vec2);
          storeu<Vec>(test_result_ptr, vec);
          test_helper.synchronize();
          allOk &= test_helper.validate();
        }
        return allOk;
   - test_name: "min_zero_case"
     requires: ["set1", "loadu", "storeu"]
     includes: ["<cstddef>"]
     implementation: |
        using T = typename Vec::base_type;
        std::size_t element_count = 1024;
        testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false};
        bool allOk = true;
        auto reference_data_ptr = test_helper.data_ref();
        auto reference_result_ptr = test_helper.result_ref();
        auto test_data_ptr = test_helper.data_target();
        auto test_result_ptr = test_helper.result_target();
        for(std::size_t i = 0; i < element_count; i += Vec::vector_element_count()){
          auto vec = set1<Vec>(0);
          storeu<Vec>(reference_result_ptr, vec);
          auto elements_vec = loadu<Vec>(&test_data_ptr[i]);
          vec = min<Vec>(vec, elements_vec);
          storeu<Vec>(test_result_ptr, vec);
          test_helper.synchronize();
          allOk &= test_helper.validate();
        }
        return allOk;
definitions:
#INTEL - AVX512
   - target_extension: "avx512"
     ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double"]
     lscpu_flags: ['avx512f']
     specialization_comment: "Signed Min"
     implementation: "return _mm512_min_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
#INTEL - AVX2
   - target_extension: "avx2"
     ctype: ["uint8_t", "uint16_t", "uint32_t", "int8_t", "int16_t", "int32_t"]
     lscpu_flags: ['avx2']
     specialization_comment: "Signed & unsigned Min"
     implementation: "return _mm256_min_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
   - target_extension: "avx2"
     ctype: ["float", "double"]
     lscpu_flags: ['avx']
     implementation: "return _mm256_min_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
   - target_extension: "avx2"
     ctype: ["int64_t", "uint64_t"]
     lscpu_flags: ['avx2']
     specialization_comment: "Takes a mask to check the smaller value of each Vector and takes that mask to get the smaller value of either vec_a or vec_b"
     is_native: False
     implementation: |
      typename Vec::register_type mask = _mm256_cmpgt_epi64(vec_a, vec_b);
      return _mm256_blendv_epi8(vec_a, vec_b, mask);
#INTEL - SSE
   - target_extension: "sse"
     ctype: ["float"]
     lscpu_flags: ['sse']
     implementation: "return _mm_min_{{intrin_tp_full[ctype]}}(vec_a, vec_b);"
   - target_extension: "sse"
     ctype: ["uint8_t", "int16_t", "double"]
     lscpu_flags: ['sse2']
     implementation: "return _mm_min_{{intrin_tp_full[ctype]}}(vec_a, vec_b);"
   - target_extension: "sse"
     ctype: ["int8_t", "uint16_t", "uint32_t", "int32_t"]
     lscpu_flags: ['sse4_1']
     implementation: "return _mm_min_{{intrin_tp_full[ctype]}}(vec_a, vec_b);"
#ARM - NEON
   - target_extension: "neon"
     ctype: ["uint8_t", "uint16_t", "uint32_t" , "int8_t", "int32_t", "double", "float"]
     lscpu_flags: ['neon']
     implementation: "return vminq_{{intrin_tp_full[ctype]}}(vec_a, vec_b);" #What about 64-Bit
#SCALAR
   - target_extension: "scalar"
     ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double"]
     lscpu_flags: []
     includes: []
     implementation: |
        if (vec_a > vec_b) return vec_b;
        return vec_a;
#INTEL - FPGA
---
primitive_name: "div"
brief_description: "Divides two vector registers."
parameters:
   - ctype: "const typename Vec::register_type"
     name: "vec_a"
     description: "First vector."
   - ctype: "const typename Vec::register_type"
     name: "vec_b"
     description: "Second vector."
returns:
   ctype: "typename Vec::register_type"
   description: "Vector containing result of the division."
testing:
   - test_name: "div_divide_vec_with_itself"
     requires: ["loadu", "storeu", "set1"]
     includes: ["<cstddef>", "<iostream>", "<algorithm>", "<limits>"]
     implementation: |
      using T = typename Vec::base_type;      
      std::size_t element_count = 0;
      if constexpr(std::is_integral_v<T>) {
        element_count = std::clamp<size_t>(std::numeric_limits<T>::max()-1, 1, 1024);
      } else {
        element_count = 1024;
      }
      testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false, testing::seq_init<T>, 1};
      bool allOk = true;
      auto reference_data_ptr = test_helper.data_ref();
      auto reference_result_ptr = test_helper.result_ref();
      auto test_data_ptr = test_helper.data_target();
      auto test_result_ptr = test_helper.result_target();
      for(std::size_t i = 0; i < element_count - Vec::vector_element_count(); i += Vec::vector_element_count()){
        auto vec = set1<Vec>(1);
        storeu<Vec>(reference_result_ptr, vec);
        std::cout << "TestData: " << (size_t)test_data_ptr[i] << "("<< type_name < Vec > () << ")" << "\n";
        auto vec_a = loadu<Vec>(&test_data_ptr[i]);
        vec = div<Vec>(vec_a, vec_a);
        storeu<Vec>(test_result_ptr, vec);
        test_helper.synchronize();
        allOk &= test_helper.validate();
      }
      return allOk;
   - test_name: "div_divide_vec_with_one"
     requires: ["loadu", "storeu", "set1"]
     includes: ["<cstddef>", "<algorithm>", "<limits>"]
     implementation: |
      using T = typename Vec::base_type;
      std::size_t element_count = 0;
      if constexpr(std::is_integral_v<T>) {
        element_count = std::clamp<size_t>(std::numeric_limits<T>::max()-1, 1, 1024);
      } else {
        element_count = 1024;
      }
      testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false, testing::seq_init<T>, 1};
      bool allOk = true;
      auto reference_data_ptr = test_helper.data_ref();
      auto reference_result_ptr = test_helper.result_ref();
      auto test_data_ptr = test_helper.data_target();
      auto test_result_ptr = test_helper.result_target();
      for(std::size_t i = 0; i < element_count - Vec::vector_element_count(); i += Vec::vector_element_count()){
        std::size_t tester_idx = 0;
        for(size_t j=i; j < i + Vec::vector_element_count(); j++){
          reference_result_ptr[tester_idx++] = reference_data_ptr[j];
        }
        auto vec = set1<Vec>(1);
        auto vec_a = loadu<Vec>(&test_data_ptr[i]);
        auto vec_result = div<Vec>(vec_a, vec);
        storeu<Vec>(test_result_ptr, vec_result);
        test_helper.synchronize();
        allOk &= test_helper.validate();
      }
      return allOk;
definitions:
#INTEL - AVX512
   - target_extension: "avx512"
     ctype: ["float", "double"]
     lscpu_flags: ["avx512f"]
     implementation: "return _mm512_div_{{intrin_tp_full[ctype]}}(vec_a, vec_b);"
   - target_extension: "avx512"
     ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
     lscpu_flags: ["avx512f"]
     is_native: False
     includes: ["<array>", "<cstddef>"]
     implementation: |
          alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_a;
          alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_b;
          _mm512_store_si512(reinterpret_cast<void*>(buffer_a.data()), vec_a);
          _mm512_store_si512(reinterpret_cast<void*>(buffer_b.data()), vec_b);
          for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
            buffer_a[i] /= buffer_b[i];
          }
          return _mm512_load_si512(reinterpret_cast<void const *>(buffer_a.data()));
#INTEL - AVX2
   - target_extension: "avx2"
     ctype: ["float", "double"]
     lscpu_flags: ['avx']
     implementation: "return _mm256_div_{{intrin_tp_full[ctype]}}(vec_a, vec_b);"
   - target_extension: "avx2"
     ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
     lscpu_flags: ['avx']
     is_native: False
     includes: ["<array>", "<cstddef>"]
     implementation: |
        alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_a;
        alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_b;
        _mm256_store_si256(reinterpret_cast<__m256i*>(buffer_a.data()), vec_a);
        _mm256_store_si256(reinterpret_cast<__m256i*>(buffer_b.data()), vec_b);
        for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
           buffer_a[i] /= buffer_b[i];
        }
        return _mm256_load_si256(reinterpret_cast<__m256i const *>(buffer_a.data()));
#INTEL - SSE
   - target_extension: "sse"
     ctype: ["float", "double"]
     lscpu_flags: ['sse']
     implementation: "return _mm_div_{{intrin_tp_full[ctype]}}(vec_a, vec_b);"
   - target_extension: "sse"
     ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
     lscpu_flags: ['sse2']
     is_native: False
     includes: ["<array>", "<cstddef>"]
     implementation: |
        alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_a;
        alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_b;
        _mm_store_si128(reinterpret_cast<__m128i*>(buffer_a.data()), vec_a);
        _mm_store_si128(reinterpret_cast<__m128i*>(buffer_b.data()), vec_b);
        for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
           buffer_a[i] /= buffer_b[i];
        }
        return _mm_load_si128(reinterpret_cast<__m128i const *>(buffer_a.data()));
#ARM - NEON - TODO: andere Bit einheiten
   - target_extension: "neon"
     ctype: ["float", "double"]
     lscpu_flags: [ 'neon' ]
     implementation: "return vdivq_{{ intrin_tp_full[ctype] }}( vec_a, vec_b );"
   - target_extension: "neon"
     ctype: ["uint64_t"]
     lscpu_flags: ['neon']
     implementation: |
      typename Vec::register_type recipocal_estimate = vshrq_n_u64(vdupq_n_u64(0xFFFFFFFFFFFFFFFF), vclzq_u64(vec_b));
      recipocal_estimate = vmulq_u64(recipocal_estimate, vsubq_u64(vdupq_n_u64(2), vmulq_u64(vec_b, recipocal_estimate)));
      typename Vec::register_type temp = vmulq_u64(vec_a, recipocal_estimate);
      temp = vqrdmulhq_u64(temp, vec_b);
      return temp;
   - target_extension: "neon"
     ctype: ["uint32_t"]
     lscpu_flags: ['neon']
     is_native: False
     implementation: |      
      typename Vec::register_type temp = vrecpe_{{intrin_tp_full[ctype]}}(vec_b);
      temp = vmulq_{{intrin_tp_full[ctype]}}(temp, vrecpsq_{{intrin_tp_full[ctype]}}(vec_b, temp));
      return vmulq_{{intrin_tp_full[ctype]}}(vec_a, temp);
   - target_extension: "neon"
     ctype: ["uint16_t"]
     lscpu_flags: ['neon']
     is_native: False
     implementation: return vdivq_u16(vec_a, vdupq_n_u16(vec_b));
   - target_extension: "neon"
     ctype: ["uint8_t"]
     lscpu_flags: ['neon']
     is_native: False
     implementation: |
      typename Vec::register_type temp = vmol_u8(vec_a);
      temp = vmulq_n_u16(temp, 0x100);
      typename Vec::register_type result = vqrdmulhq_u8(temp, vec_b);
      result = vshrn_n_u16(result, 8);
      return result;
#SCALAR
   - target_extension: "scalar"
     ctype: [ "uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double" ]
     lscpu_flags: [ ]
     implementation: return vec_a / vec_b;
#INTEL - FPGA
---
primitive_name: "hor"
brief_description: "Operates horizontal OR on vector register"
parameters:
   - ctype: "const typename Vec::register_type"
     name: "vec"
     description: "Operating Vector"
returns:
   ctype: "typename Vec::base_type"
   description: "Result of the horizontal OR"
testing:
   - test_name: "with_only_zero"
     requires: ["set1", "loadu", "storeu"]
     includes: ["<cstddef>"]
     implementation: |
        using T = typename Vec::base_type;
        testing::test_memory_helper_t<Vec> test_helper{1, false};
        auto reference_result_ptr = test_helper.result_ref();
        auto test_result_ptr = test_helper.result_target();
        auto vec = set1<Vec>(0);
        *reference_result_ptr = 0;
        *test_result_ptr = hor<Vec>(vec);
        test_helper.synchronize();
        return test_helper.validate();
   - test_name: "with_only_one"
     requires: ["set1", "loadu", "storeu"]
     includes: ["<cstddef>"]
     implementation: |
        using T = typename Vec::base_type;
        testing::test_memory_helper_t<Vec> test_helper{1, false};
        auto reference_result_ptr = test_helper.result_ref();
        auto test_result_ptr = test_helper.result_target();
        auto vec = set1<Vec>(1);
        *reference_result_ptr = 1;
        *test_result_ptr = hor<Vec>(vec);
        test_helper.synchronize();
        return test_helper.validate();
   - test_name: "with_rand_values"
     requires: ["loadu", "storeu"]
     includes: ["<cstddef>"]
     implementation: |
      using T = typename Vec::base_type;
      std::size_t element_count = 1024;
      testing::test_memory_helper_t<Vec> test_helper{element_count, 1, false};
      bool allOk = true;
      auto reference_data_ptr = test_helper.data_ref();
      auto reference_result_ptr = test_helper.result_ref();
      auto test_data_ptr = test_helper.data_target();
      auto test_result_ptr = test_helper.result_target();
      for(std::size_t i = 0; i < element_count; i += Vec::vector_element_count()){
        auto vec = loadu<Vec>(&test_data_ptr[i]);
        if constexpr (std::is_same_v<T, float> || std::is_same_v<T, double>){
          typename std::conditional<std::is_same_v<T, float>, int32_t, 
          typename std::conditional<std::is_same_v<T, double>, int64_t, void>::type>::type result = 0;
          union {
              T val;
              typename std::conditional<std::is_same_v<T, float>, int32_t, 
              typename std::conditional<std::is_same_v<T, double>, int64_t, void>::type>::type i_val;
            } u;
          for(size_t j=i; j < i + Vec::vector_element_count(); j++){
            u.val = reference_data_ptr[j];
            result |= u.i_val;
          }
          u.val = hor<Vec>(vec);
          allOk &= (result == u.i_val);
        }
        else{
          std::size_t result = 0;
          for(size_t j=i; j < i + Vec::vector_element_count(); j++){
          result |= reference_data_ptr[j];
          }
          auto vec_result = hor<Vec>(vec);
          * reference_result_ptr = result;
          * test_result_ptr = vec_result;
          test_helper.synchronize();
          allOk &= test_helper.validate();
        }
      }
      return allOk;
definitions:
#INTEL - AVX512
   - target_extension: "avx512"
     ctype: ["int8_t", "uint8_t"]
     lscpu_flags: ['avx512dq']
     implementation: |
      uint32_t temp = _mm512_reduce_or_epi32(vec);
      return (temp & 0xFF) | ((temp >> 8) & 0xFF) | ((temp >> 16) & 0xFF) | (temp >> 24);

      /* Generated by ChatGPT
      Vec::register_type temp = vec;
      Vec::register_type permuted = _mm512_permutexvar_epi64(_mm512_set_epi64(7, 3, 6, 2, 5, 1, 4, 0), temp);
      temp = _mm512_or_si512(temp, permuted);
      Vec::register_type shuffled = _mm512_shuffle_i32x4(temp, temp, _MM_SHUFFLE(1, 0, 3, 2));
      temp = _mm512_or_si512(temp, shuffled);
      Vec::register_type shuf = _mm512_set_epi{{intrin_tp[ctype][1]}}(
              56, 48, 40, 32, 24, 16, 8, 0,
              56, 48, 40, 32, 24, 16, 8, 0,
              56, 48, 40, 32, 24, 16, 8, 0,
              56, 48, 40, 32, 24, 16, 8, 0,
              56, 48, 40, 32, 24, 16, 8, 0,
              56, 48, 40, 32, 24, 16, 8, 0,
              56, 48, 40, 32, 24, 16, 8, 0,
              56, 48, 40, 32, 24, 16, 8, 0
      );
      Vec::register_type shuf_result = _mm512_shuffle_epi8(temp, shuf);
      Vec::register_type or_result = _mm512_or_si512(temp, shuf_result);
      __m128i low = _mm512_castsi512_si128(or_result);
      return _mm_extract_epi{{intrin_tp[ctype][1]}}(low, 0);*/
   - target_extension: "avx512"
     ctype: ["uint16_t", "int16_t"]
     lscpu_flags: [ 'avx512dq' ]
     implementation: |
      uint32_t temp = _mm512_reduce_or_epi32(vec);
      return (temp & 0xFFFF) | (temp >> 16);
   - target_extension: "avx512"
     ctype: ["uint32_t", "int32_t", "int64_t", "uint64_t"]
     lscpu_flags: [ 'avx512dq' ]
     implementation: return _mm512_reduce_or_epi{{intrin_tp[ctype][1]}}(vec);
   - target_extension: "avx512"
     ctype: ["float"]
     lscpu_flags: [ 'avx512dq' ]
     implementation: |
      union{
        float val;
        int32_t i_val;
      }u;
      u.i_val = _mm512_reduce_or_epi32(_mm512_castps_si512(vec));
      return u.val;
   - target_extension: "avx512"
     ctype: ["double"]
     lscpu_flags: [ 'avx512dq' ]
     implementation: |
      union{
        double val;
        int64_t i_val;
      }u;
      u.i_val = _mm512_reduce_or_epi64(_mm512_castpd_si512(vec));
      return u.val;
#INTEL - AVX2
   - target_extension: "avx2"
     ctype: ["int8_t", "uint8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "int64_t", "uint64_t"]
     lscpu_flags: [ 'avx2', 'sse2' ]
     implementation: |
      //to have all value types in one func, but doesnt work this way for some reason
      __m128i temp = _mm_or_si128(_mm256_extracti128_si256(vec, 0), _mm256_extracti128_si256(vec, 1));
      temp = _mm_or_si128(temp, _mm_srli_si128(temp, 8));
      {% if ctype != "int64_t" and ctype != "uint64_t" %}
      temp = _mm_or_si128(temp, _mm_srli_si128(temp, 4));
      {% endif %}
      {% if ctype == "int16_t" or ctype == "uint16_t" %}
      temp = _mm_or_si128(temp, _mm_srli_si128(temp, 2));
      {% endif %}
      {% if ctype == "int8_t" or ctype == "uint8_t" %}
      temp = _mm_or_si128(temp, _mm_srli_si128(temp, 2));
      temp = _mm_or_si128(temp, _mm_srli_si128(temp, 1));
      {% endif %}
      return _mm_extract_epi{{intrin_tp[ctype][1]}}(temp, 0);
   - target_extension: "avx2"
     ctype: ["float"]
     lscpu_flags: [ 'avx2', 'sse2' ]
     implementation: |
      __m256i as_int = _mm256_castps_si256(vec);  //convert to int
      __m128i temp = _mm_or_si128(_mm256_extracti128_si256(as_int, 0), _mm256_extracti128_si256(as_int, 1));
      temp = _mm_or_si128(temp, _mm_srli_si128(temp, 8));
      temp = _mm_or_si128(temp, _mm_srli_si128(temp, 4));
      __m128 as_float = _mm_castsi128_ps(temp);
      return _mm_cvtss_f32(as_float);
   - target_extension: "avx2"
     ctype: ["double"]
     lscpu_flags: [ 'avx2', 'sse2' ]
     implementation: |
      __m256i as_int = _mm256_castpd_si256(vec);  //convert to int
      __m128i temp = _mm_or_si128(_mm256_extracti128_si256(as_int, 0), _mm256_extracti128_si256(as_int, 1));
      temp = _mm_or_si128(temp, _mm_srli_si128(temp, 8));
      __m128d as_double = _mm_castsi128_pd(temp);
      return _mm_cvtsd_f64(as_double);
#INTEL - SSE
   - target_extension: "sse"
     ctype: ["uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t", "uint8_t", "int8_t"]
     lscpu_flags: [ 'sse2' ]
     implementation: |
        // Reduce Lanes dependend on datatype 
        Vec::register_type temp = _mm_or_si128(vec, _mm_srli_si128(vec, 8));
        {% if ctype != "int64_t" and ctype != "uint64_t" %}
        temp = _mm_or_si128(temp, _mm_srli_si128(temp, 4));
        {% endif %}
        {% if ctype == "int16_t" or ctype == "uint16_t" %}
        temp = _mm_or_si128(temp, _mm_srli_si128(temp, 2));
        {% endif %}
        {% if ctype == "int8_t" or ctype == "uint8_t" %}
        temp = _mm_or_si128(temp, _mm_srli_si128(temp, 2));
        temp = _mm_or_si128(temp, _mm_srli_si128(temp, 1));
        {% endif %}
        return _mm_extract_epi{{intrin_tp[ctype][1]}}(temp, 0);
   - target_extension: "sse"
     ctype: ["float"]
     lscpu_flags: ['sse2']
     implementation: |
      __m128i temp = _mm_castps_si128(vec);  //convert to int
      temp = _mm_or_si128(temp, _mm_srli_si128(temp, 8));
      temp = _mm_or_si128(temp, _mm_srli_si128(temp, 4));
      __m128 as_float = _mm_castsi128_ps(temp);
      return _mm_cvtss_f32(as_float);      
   - target_extension: "sse"
     ctype: ["double"]
     lscpu_flags: [ 'sse2' ]
     implementation: |
      __m128i temp = _mm_castpd_si128(vec);  //convert to int
      temp = _mm_or_si128(temp, _mm_srli_si128(temp, 8));
      __m128d as_double = _mm_castsi128_pd(temp);
      return _mm_cvtsd_f64(as_double);
#SCALAR
   - target_extension: "scalar"
     ctype: [ "uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double"]
     lscpu_flags: [ ]
     implementation: "return vec;"
#ARM - NEON
#INTEL - FPGA
---
primitive_name: "inv"
brief_description: "Bitwise invertion values in vector Register."
parameters:
   - ctype: "const typename Vec::register_type"
     name: "vec"
     description: "Operating Vector"
returns:
   ctype: "typename Vec::register_type"
   description: "Result of the invertion."
testing:
   - test_name: "with_only_zero"
     requires: ["set1", "loadu", "storeu"]
     includes: ["<cstddef>","<algorithm>", "<limits>"]
     implementation: |
        using T = typename Vec::base_type;
        testing::test_memory_helper_t<Vec> test_helper{Vec::vector_element_count(), false};
        auto reference_result_ptr = test_helper.result_ref();
        auto test_result_ptr = test_helper.result_target();
        auto vec = set1<Vec>(0);
        if constexpr (std::is_same_v<T, float> || std::is_same_v<T, double>){
          T data[Vec::vector_element_count()];
          storeu<Vec>(data, vec);
          storeu<Vec>(test_result_ptr, inv<Vec>(vec));
          for(int i = 0; i < Vec::vector_element_count(); i ++){
            union {
              T f_val;
              typename std::conditional<std::is_same_v<T, float>, int32_t, 
              typename std::conditional<std::is_same_v<T, double>, int64_t, void>::type>::type i_val;
            } u;
            u.f_val = test_result_ptr[i];
            union {
              T f_val;
              typename std::conditional<std::is_same_v<T, float>, int32_t, 
              typename std::conditional<std::is_same_v<T, double>, int64_t, void>::type>::type i_val;
            } v;
            v.f_val = data[i];
            v.i_val = ~v.i_val;
            return (u.i_val == v.i_val);
          }
        }
        else{
          storeu<Vec>(reference_result_ptr, ~vec);
          storeu<Vec>(test_result_ptr, inv<Vec>(vec));
          test_helper.synchronize();
          return test_helper.validate();
        }
   - test_name: "with_only_ones"
     requires: ["set1", "loadu", "storeu"]
     includes: ["<cstddef>", "<algorithm>", "<limits>"]
     implementation: |
        using T = typename Vec::base_type;
        testing::test_memory_helper_t<Vec> test_helper{Vec::vector_element_count(), false};
        auto reference_result_ptr = test_helper.result_ref();
        auto test_result_ptr = test_helper.result_target();
        auto vec = set1<Vec>(~0);
        if constexpr (std::is_same_v<T, float> || std::is_same_v<T, double>){
          T data[Vec::vector_element_count()];
          storeu<Vec>(data, vec);
          storeu<Vec>(test_result_ptr, inv<Vec>(vec));
          for(int i = 0; i < Vec::vector_element_count(); i ++){
            union {
              T f_val;
              typename std::conditional<std::is_same_v<T, float>, int32_t, 
              typename std::conditional<std::is_same_v<T, double>, int64_t, void>::type>::type i_val;
            } u;
            u.f_val = test_result_ptr[i];
            union {
              T f_val;
              typename std::conditional<std::is_same_v<T, float>, int32_t, 
              typename std::conditional<std::is_same_v<T, double>, int64_t, void>::type>::type i_val;
            } v;
            v.f_val = data[i];
            v.i_val = ~v.i_val;
            return (u.i_val == v.i_val);
          }
        }
        else{
          storeu<Vec>(reference_result_ptr, ~vec);
          storeu<Vec>(test_result_ptr, inv<Vec>(vec));
          test_helper.synchronize();
          return test_helper.validate();
        }
   - test_name: "with_rand_values"
     requires: ["loadu", "storeu"]
     includes: ["<cstddef>"]
     implementation: |
      using T = typename Vec::base_type;
      std::size_t element_count = 1024;
      testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false};
      bool allOk = true;
      auto reference_data_ptr = test_helper.data_ref();
      auto reference_result_ptr = test_helper.result_ref();
      auto test_data_ptr = test_helper.data_target();
      auto test_result_ptr = test_helper.result_target();
      for(std::size_t i = 0; i < element_count; i += Vec::vector_element_count()){
        auto vec = loadu<Vec>(&test_data_ptr[i]);
        if constexpr (std::is_same_v<T, float> || std::is_same_v<T, double>){
          T data[Vec::vector_element_count()];
          storeu<Vec>(data, vec);
          storeu<Vec>(test_result_ptr, inv<Vec>(vec));
          for(int i = 0; i < Vec::vector_element_count(); i ++){
            union {
              T f_val;
              typename std::conditional<std::is_same_v<T, float>, int32_t, 
              typename std::conditional<std::is_same_v<T, double>, int64_t, void>::type>::type i_val;
            } u;
            u.f_val = test_result_ptr[i];
            union {
              T f_val;
              typename std::conditional<std::is_same_v<T, float>, int32_t, 
              typename std::conditional<std::is_same_v<T, double>, int64_t, void>::type>::type i_val;
            } v;
            v.f_val = data[i];
            v.i_val = ~v.i_val;
            allOk &= (u.i_val == v.i_val);
          }
        }
        else{
          storeu<Vec>(reference_result_ptr, ~vec);
          storeu<Vec>(test_result_ptr, inv<Vec>(vec));
          test_helper.synchronize();
          allOk &= test_helper.validate();
        }
      }
      return allOk;
definitions:
#INTEL - AVX512
   - target_extension: "avx512"
     ctype: ["uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t", "uint8_t", "int8_t"]
     lscpu_flags: [ 'avx512f' ]
     implementation: |
      Vec::register_type all_ones = _mm512_set1_epi32(-1);
      return _mm512_xor_epi32(vec, all_ones);
   - target_extension: "avx512"
     ctype: ["float", "double"]
     lscpu_flags: [ 'avx512f' ]
     implementation: |
      __m512i all_ones = _mm512_set1_epi32(-1);
      __m512i as_int = _mm512_cast{{intrin_tp_full[ctype]}}_si512(vec);
      return _mm512_castsi512_{{intrin_tp_full[ctype]}}(_mm512_xor_epi32(as_int, all_ones));
#INTEL - AVX2
   - target_extension: "avx2"
     ctype: ["uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t", "uint8_t", "int8_t"]
     lscpu_flags: [ 'avx2' ]
     implementation: |
      Vec::register_type all_ones = _mm256_set1_epi32(-1);
      return _mm256_xor_si256(vec, all_ones);
   - target_extension: "avx2"
     ctype: ["float", "double"]
     lscpu_flags: [ 'avx2' ]
     implementation: |
      __m256i all_ones = _mm256_set1_epi32(-1);
      __m256i as_int = _mm256_cast{{intrin_tp_full[ctype]}}_si256(vec);
      return _mm256_castsi256_{{intrin_tp_full[ctype]}}(_mm256_xor_si256(as_int, all_ones));
#INTEL - SSE
   - target_extension: "sse"
     ctype: ["uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t", "uint8_t", "int8_t"]
     lscpu_flags: [ 'sse2' ]
     implementation: |
      Vec::register_type all_ones = _mm_set1_epi32(-1);
      return _mm_xor_si128(vec, all_ones);
   - target_extension: "sse"
     ctype: ["float", "double"]
     lscpu_flags: [ 'sse2' ]
     implementation: |
      __m128i all_ones = _mm_set1_epi32(-1);
      __m128i as_int = _mm_cast{{intrin_tp_full[ctype]}}_si128(vec);
      return _mm_castsi128_{{intrin_tp_full[ctype]}}(_mm_xor_si128(as_int, all_ones));
#SCALAR
   - target_extension: "scalar"
     ctype: [ "uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
     lscpu_flags: [ ]
     implementation: "return ~vec;"
   - target_extension: "scalar"
     ctype: [ "float", "double" ]
     lscpu_flags: [ ]
     implementation: |
      {% if ctype == "float" %}
      union {
        float val;
        int32_t i_val;
      } u;
      {% else %}
      union {
        double val;
        int64_t i_val;
      } u;
      {% endif %}
      u.val = vec;
      u.i_val = ~u.i_val;
      return u.val;
...